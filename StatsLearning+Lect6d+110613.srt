0
00:00:00,270 --> 00:00:01,660
OK.

1
00:00:01,660 --> 00:00:04,570
Now we slipped one thing by you.

2
00:00:04,570 --> 00:00:09,920
We said in South Africa the risk for heart disease is

3
00:00:09,920 --> 00:00:14,450
about 5% in this age category.

4
00:00:14,450 --> 00:00:19,400
But in our sample, we&#39;ve got 160 cases and 302 controls, so

5
00:00:19,400 --> 00:00:24,850
in the sample we&#39;re showing a risk of 0.35.

6
00:00:24,850 --> 00:00:27,020
It seems like the model is going to be off.

7
00:00:27,020 --> 00:00:30,440
It&#39;s going to estimate probabilities too high.

8
00:00:30,440 --> 00:00:34,520
Well, case-control sampling is one of the favorite tools in

9
00:00:34,520 --> 00:00:35,990
epidemiology.

10
00:00:35,990 --> 00:00:39,280
Especially when you have a rare disease, you take all the

11
00:00:39,280 --> 00:00:41,620
cases you can find, and then you can just

12
00:00:41,620 --> 00:00:43,900
sample from the controls.

13
00:00:43,900 --> 00:00:47,810
The reason is that for the logistic regression model it

14
00:00:47,810 --> 00:00:50,720
turns out that you can estimate the regression

15
00:00:50,720 --> 00:00:53,690
parameters of interest-- these of the coefficients of the x&#39;s

16
00:00:53,690 --> 00:00:54,640
in this case--

17
00:00:54,640 --> 00:00:56,090
accurately.

18
00:00:56,090 --> 00:00:58,770
That&#39;s if the model&#39;s correct.

19
00:00:58,770 --> 00:01:01,390
But the constant term will be incorrect.

20
00:01:01,390 --> 00:01:04,330
Then you can just go ahead and correct the constant too by a

21
00:01:04,330 --> 00:01:06,140
simple transformation.

22
00:01:06,140 --> 00:01:09,120
And in fact, for those that are interested, I just give

23
00:01:09,120 --> 00:01:11,170
you the transformation.

24
00:01:11,170 --> 00:01:16,440
So pi [INAUDIBLE] here is the apparent risk of heart

25
00:01:16,440 --> 00:01:20,910
disease, in this case in our population, which is 0.35.

26
00:01:20,910 --> 00:01:24,580
And after all, this is just the logit transformation of

27
00:01:24,580 --> 00:01:30,120
the prior probability or the prior apparent probability.

28
00:01:30,120 --> 00:01:32,810
And here&#39;s the logit transformation of the true

29
00:01:32,810 --> 00:01:37,300
risk, which is pi, in this case, 0.05.

30
00:01:37,300 --> 00:01:39,770
And so we take the logit transformation of those two,

31
00:01:39,770 --> 00:01:41,360
and we correct the intercept.

32
00:01:41,360 --> 00:01:43,940
This is the currently estimated intercept.

33
00:01:43,940 --> 00:01:47,360
We correct it by adding in the log odds of the true

34
00:01:47,360 --> 00:01:49,910
probability, subtract the apparent one.

35
00:01:49,910 --> 00:01:51,520
That correct the intercept.

36
00:01:51,520 --> 00:01:54,250
Maybe it&#39;s worth saying a little bit about case-control

37
00:01:54,250 --> 00:01:56,870
sampling, why the sampling&#39;s done this way.

38
00:01:56,870 --> 00:01:59,070
One thing we could have done instead, or the investors

39
00:01:59,070 --> 00:02:01,770
could have done was to take maybe 1,000 people and to

40
00:02:01,770 --> 00:02:05,170
follow them for 20 years and to record their risk factors

41
00:02:05,170 --> 00:02:07,080
and then see who gets heart disease.

42
00:02:07,080 --> 00:02:09,850
We think about 5% will get heart disease.

43
00:02:09,850 --> 00:02:12,250
That&#39;s a valid thing to do, but the problem is it takes 20

44
00:02:12,250 --> 00:02:15,180
years and maybe more than a few thousand

45
00:02:15,180 --> 00:02:16,410
people to get enough--

46
00:02:16,410 --> 00:02:17,670
Actually, with 1,000 people, we&#39;d get,

47
00:02:17,670 --> 00:02:19,616
what 50 cases, right?

48
00:02:19,616 --> 00:02:20,910
Right.

49
00:02:20,910 --> 00:02:22,110
So that&#39;s not very practical.

50
00:02:22,110 --> 00:02:24,390
We need a large sample, and we need many years to do it.

51
00:02:24,390 --> 00:02:24,720
Right.

52
00:02:24,720 --> 00:02:26,870
Case-control sampling says, well, let&#39;s not do things

53
00:02:26,870 --> 00:02:27,940
prospectively like that.

54
00:02:27,940 --> 00:02:30,860
Let&#39;s rather find people who we already know have heart

55
00:02:30,860 --> 00:02:35,770
disease or don&#39;t have heart disease and then sample them.

56
00:02:35,770 --> 00:02:40,280
Now in the proportion in this case, we&#39;ll take 160 cases and

57
00:02:40,280 --> 00:02:44,220
302 controls and then record their risk factors.

58
00:02:44,220 --> 00:02:46,410
We start with cases and controls, and

59
00:02:46,410 --> 00:02:47,480
we get lots of cases.

60
00:02:47,480 --> 00:02:49,090
And we do this without waiting 20 years.

61
00:02:49,090 --> 00:02:50,610
We can do it right now.

62
00:02:50,610 --> 00:02:51,890
And then we record the risk factors.

63
00:02:51,890 --> 00:02:52,953
That&#39;s a good point, [INAUDIBLE].

64
00:02:52,953 --> 00:02:53,640
Yeah.

65
00:02:53,640 --> 00:02:57,130
And that&#39;s very popular in epidemiology.

66
00:02:57,130 --> 00:03:00,470
There are other issues involved with case-control

67
00:03:00,470 --> 00:03:02,115
sampling, retrospective sampling.

68
00:03:02,115 --> 00:03:04,550
Yeah.

69
00:03:04,550 --> 00:03:05,700
We won&#39;t take that up now.

70
00:03:05,700 --> 00:03:08,690
But that&#39;s the reason it&#39;s so popular.

71
00:03:08,690 --> 00:03:15,000
On the same issue, in many modern data sets, we&#39;ll have

72
00:03:15,000 --> 00:03:17,020
very imbalanced situations.

73
00:03:17,020 --> 00:03:19,070
For example, if you&#39;re modelling the click-through

74
00:03:19,070 --> 00:03:23,830
rate on an ad on a web page, the probability of someone

75
00:03:23,830 --> 00:03:29,380
clicking is less than 1%, maybe 0.005 or even smaller,

76
00:03:29,380 --> 00:03:34,410
0.001, which means if you just take a random sample of

77
00:03:34,410 --> 00:03:37,370
subjects who&#39;ve been exposed to ads, you&#39;re going to get

78
00:03:37,370 --> 00:03:41,190
very, very few 1&#39;s and a huge amount of 0&#39;s.

79
00:03:41,190 --> 00:03:42,930
OK?

80
00:03:42,930 --> 00:03:44,650
And these data sets get really large.

81
00:03:44,650 --> 00:03:48,550
So the question is, do we need to use all of that 0, 1 data

82
00:03:48,550 --> 00:03:49,540
to fit the models?

83
00:03:49,540 --> 00:03:51,860
Well, from what we&#39;ve told you, no.

84
00:03:51,860 --> 00:03:54,580
You can take a sample of the controls.

85
00:03:54,580 --> 00:03:59,080
And this picture over here just gives an indication of

86
00:03:59,080 --> 00:04:00,330
the trade-off.

87
00:04:02,370 --> 00:04:05,850
The main point is that ultimately the variance of

88
00:04:05,850 --> 00:04:09,920
your parameter estimates has to do with the number of cases

89
00:04:09,920 --> 00:04:12,210
that you got, which is the smaller class.

90
00:04:12,210 --> 00:04:15,110
And so what this plot shows is it&#39;s showing the variance of

91
00:04:15,110 --> 00:04:20,940
the coefficients as a function of the case-control ratio, in

92
00:04:20,940 --> 00:04:23,310
fact the control case ratio.

93
00:04:23,310 --> 00:04:26,300
What it says is when you&#39;ve got about 5 or 6 to 1, the

94
00:04:26,300 --> 00:04:29,410
variance kind of levels off here.

95
00:04:29,410 --> 00:04:31,450
And so there&#39;s diminishing returns in

96
00:04:31,450 --> 00:04:33,570
getting even more controls.

97
00:04:33,570 --> 00:04:37,810
So if you&#39;ve got a very sparse situation, sample about 5 or 6

98
00:04:37,810 --> 00:04:42,070
controls for every case, and now you can work with a much

99
00:04:42,070 --> 00:04:43,740
more manageable data set.

100
00:04:43,740 --> 00:04:46,330
So it&#39;s very handy, especially in modern

101
00:04:46,330 --> 00:04:49,680
extremely large data sets.

102
00:04:49,680 --> 00:04:53,000
Just a comment about what this case-control sampling is.

103
00:04:53,000 --> 00:04:55,910
The most obvious way to study the risk factors for heart

104
00:04:55,910 --> 00:04:58,720
disease would be to take a large group of people, maybe

105
00:04:58,720 --> 00:05:02,280
1,000 or 100,000 people, follow them for maybe 20

106
00:05:02,280 --> 00:05:04,990
years, record their risk factors, and see who gets

107
00:05:04,990 --> 00:05:06,860
heart disease and who doesn&#39;t after 20 years.

108
00:05:06,860 --> 00:05:09,010
If you&#39;re still around.

109
00:05:09,010 --> 00:05:09,920
If we&#39;re still around.

110
00:05:09,920 --> 00:05:11,160
Right.

111
00:05:11,160 --> 00:05:14,650
Now that actually is a good way to do things, except it&#39;s

112
00:05:14,650 --> 00:05:16,300
very expensive and it takes a long time.

113
00:05:16,300 --> 00:05:17,930
You have to get a lot of people, and you have to wait

114
00:05:17,930 --> 00:05:19,220
for many years.

115
00:05:19,220 --> 00:05:21,600
Case-control sampling is a lot more attractive.

116
00:05:21,600 --> 00:05:25,190
Because what you do is rather than taking people and

117
00:05:25,190 --> 00:05:27,940
following them forward in time, you sample people who

118
00:05:27,940 --> 00:05:30,480
you know have heart disease.

119
00:05:30,480 --> 00:05:32,700
You also get a comparison sample of people who do not

120
00:05:32,700 --> 00:05:34,670
have heart disease, the controls.

121
00:05:34,670 --> 00:05:36,380
And then you record their risk factors.

122
00:05:36,380 --> 00:05:38,870
So it&#39;s much cheaper, and it&#39;s much quicker to do.

123
00:05:38,870 --> 00:05:41,130
And that&#39;s why case-control sampling is a very commonly

124
00:05:41,130 --> 00:05:43,480
used technique in epidemiology.

125
00:05:43,480 --> 00:05:43,730
OK.

126
00:05:43,730 --> 00:05:47,600
What if we have more than two classes?

127
00:05:47,600 --> 00:05:50,200
Can we still do logistic regression?

128
00:05:50,200 --> 00:05:52,530
Well, we can.

129
00:05:52,530 --> 00:05:56,140
It easy generalizes to more than two classes.

130
00:05:56,140 --> 00:05:57,570
There&#39;s various ways of doing this.

131
00:05:57,570 --> 00:06:01,370
And one version-- which actually is how we do it in

132
00:06:01,370 --> 00:06:04,230
the glmnet package in R, which you&#39;ll will be

133
00:06:04,230 --> 00:06:05,910
learning more about--

134
00:06:05,910 --> 00:06:11,620
is we have this exponential form that we saw before but

135
00:06:11,620 --> 00:06:13,970
modified for multiple classes.

136
00:06:13,970 --> 00:06:16,480
So notice in the numerator we&#39;ve got an e

137
00:06:16,480 --> 00:06:19,620
to the linear model.

138
00:06:19,620 --> 00:06:22,400
And this is for the probability that Y is k given

139
00:06:22,400 --> 00:06:24,170
X, a small k.

140
00:06:24,170 --> 00:06:28,410
And we&#39;ve got, say, capital K classes, where capital K is

141
00:06:28,410 --> 00:06:30,020
bigger than 2.

142
00:06:30,020 --> 00:06:33,850
In the denominator, we&#39;ve just got the sum of those

143
00:06:33,850 --> 00:06:36,830
exponentials for all the classes.

144
00:06:36,830 --> 00:06:41,680
In this case, each class gets its own linear model.

145
00:06:41,680 --> 00:06:44,780
And then we just weigh them against each other with this

146
00:06:44,780 --> 00:06:47,220
exponential function, sometimes

147
00:06:47,220 --> 00:06:49,740
called the softmax function.

148
00:06:49,740 --> 00:06:50,990
OK?

149
00:06:53,650 --> 00:06:55,730
The mathier students would recognize that some

150
00:06:55,730 --> 00:07:00,720
cancellation is possible in this ratio.

151
00:07:00,720 --> 00:07:02,350
And that&#39;s true.

152
00:07:02,350 --> 00:07:06,090
What that means is actually you only need K minus 1 linear

153
00:07:06,090 --> 00:07:10,920
functions, as you do in a 2-class logistic regression.

154
00:07:10,920 --> 00:07:12,560
That&#39;s somewhat of a detail.

155
00:07:12,560 --> 00:07:16,270
It turns out for our glmnet application this is a more

156
00:07:16,270 --> 00:07:19,525
symmetric representation, and it&#39;s actually more useful.

157
00:07:22,550 --> 00:07:25,130
This multiclass logistic regression is also referred to

158
00:07:25,130 --> 00:07:26,510
as multinominal regression.

