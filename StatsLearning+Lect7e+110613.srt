0
00:00:00,000 --> 00:00:01,970
OK, so we&#39;re back.

1
00:00:01,970 --> 00:00:03,380
Some more discussion of the bootstrap--

2
00:00:03,380 --> 00:00:04,850
we saw an example of the bootstrap with the

3
00:00:04,850 --> 00:00:05,900
investments.

4
00:00:05,900 --> 00:00:07,530
And now, in general, we&#39;re going to talk about the

5
00:00:07,530 --> 00:00:11,000
bootstrap and think about it in more complex situations.

6
00:00:11,000 --> 00:00:12,570
So here&#39;s a schematic, which I think is

7
00:00:12,570 --> 00:00:13,760
very useful, actually.

8
00:00:13,760 --> 00:00:16,940
It&#39;s due to David Friedman at Berkeley.

9
00:00:16,940 --> 00:00:20,540
It&#39;s the real world bootstrap worldview of the bootstrap.

10
00:00:20,540 --> 00:00:23,150
So on the left, we have a cloud.

11
00:00:23,150 --> 00:00:27,700
And the ingredients we&#39;re imagining-- there&#39;s a real

12
00:00:27,700 --> 00:00:32,659
population that gives our data, which I&#39;m calling

13
00:00:32,659 --> 00:00:35,880
genetically Z, observations Z1 through Zn.

14
00:00:35,880 --> 00:00:37,790
So these are like our training data?

15
00:00:37,790 --> 00:00:39,130
Right, that&#39;s our training data.

16
00:00:39,130 --> 00:00:42,790
For example, in the investment example we just saw, this

17
00:00:42,790 --> 00:00:46,980
training data was a set of investments x, y--

18
00:00:46,980 --> 00:00:51,655
x1, y1 to xn, yn.

19
00:00:51,655 --> 00:00:55,920
All right, but we&#39;re going to call each of these pairs a Z,

20
00:00:55,920 --> 00:00:57,840
Z1 through Zn.

21
00:00:57,840 --> 00:01:01,470
So we imagined in that situation that we have our

22
00:01:01,470 --> 00:01:05,170
training data from a population of investments.

23
00:01:05,170 --> 00:01:06,270
This is in the real world.

24
00:01:06,270 --> 00:01:07,720
We have a training sample.

25
00:01:07,720 --> 00:01:10,600
And from that training sample, we derive a

26
00:01:10,600 --> 00:01:11,810
statistic, an estimate.

27
00:01:11,810 --> 00:01:15,890
In that particular case, it was the alpha hat, which is

28
00:01:15,890 --> 00:01:22,400
the optimal proportion of investments for x.

29
00:01:22,400 --> 00:01:25,280
So this is a summary, in a sense, of what we did in the

30
00:01:25,280 --> 00:01:28,220
investment example for our training data.

31
00:01:28,220 --> 00:01:30,680
And what we wanted to get was an idea of the standard error

32
00:01:30,680 --> 00:01:32,600
of alpha hat.

33
00:01:32,600 --> 00:01:36,740
Now, we made the point earlier that ideally, if we had access

34
00:01:36,740 --> 00:01:38,410
to the population, we could get more training data.

35
00:01:38,410 --> 00:01:41,880
We could simply grab more samples of training data from

36
00:01:41,880 --> 00:01:45,350
the population, more investments from the possible

37
00:01:45,350 --> 00:01:46,160
population investments.

38
00:01:46,160 --> 00:01:48,356
You mean like a new sample, the same size?

39
00:01:48,356 --> 00:01:50,210
Yeah, exactly, a new sample--

40
00:01:50,210 --> 00:01:53,340
and from the new sample, do the same analysis, get an

41
00:01:53,340 --> 00:01:55,630
estimate alpha hat, and do that many times.

42
00:01:55,630 --> 00:01:58,360
And we showed how you could do that on the computer in the

43
00:01:58,360 --> 00:01:59,320
previous example.

44
00:01:59,320 --> 00:02:01,740
But we made the point that not often can you actually do that

45
00:02:01,740 --> 00:02:02,270
in practice.

46
00:02:02,270 --> 00:02:03,870
Because you don&#39;t have access to the population.

47
00:02:03,870 --> 00:02:05,880
You can&#39;t get more training data, typically.

48
00:02:05,880 --> 00:02:07,970
What you have to work with is just your

49
00:02:07,970 --> 00:02:09,210
given training example.

50
00:02:09,210 --> 00:02:12,945
So a way of thinking of the bootstrap in the abstract is

51
00:02:12,945 --> 00:02:15,260
to say, well, we don&#39;t have access to the population.

52
00:02:15,260 --> 00:02:20,650
Let&#39;s replace the population, which we don&#39;t have, by P hat,

53
00:02:20,650 --> 00:02:26,290
which in the bootstrap&#39;s case is the training sample itself.

54
00:02:26,290 --> 00:02:30,460
It&#39;s a population that puts probability 1 over n, n being

55
00:02:30,460 --> 00:02:32,560
the sample size, on each of the training points.

56
00:02:32,560 --> 00:02:35,400
So it says, our guess for the population--

57
00:02:35,400 --> 00:02:36,890
which we don&#39;t have access to but we have

58
00:02:36,890 --> 00:02:38,450
from a training sample--

59
00:02:38,450 --> 00:02:40,550
is we have no more information.

60
00:02:40,550 --> 00:02:42,980
We&#39;re going to say with equal probability, a training point

61
00:02:42,980 --> 00:02:45,850
can come from the first point we saw, the second point we

62
00:02:45,850 --> 00:02:47,590
saw, up to the nth point we saw.

63
00:02:47,590 --> 00:02:49,270
So that&#39;s what we&#39;ll call P hat--

64
00:02:49,270 --> 00:02:50,935
the empirical distribution function.

65
00:02:50,935 --> 00:02:53,130
That&#39;s another name for that--

66
00:02:53,130 --> 00:02:56,880
empirical distribution function.

67
00:02:56,880 --> 00:02:58,680
So when you draw from this empirical distribution

68
00:02:58,680 --> 00:03:03,870
function, that is sampling with replacement.

69
00:03:03,870 --> 00:03:05,170
And that&#39;s what the bootstrap does, right?

70
00:03:05,170 --> 00:03:07,210
It samples--

71
00:03:07,210 --> 00:03:09,960
we saw that we draw samples with replacement from the

72
00:03:09,960 --> 00:03:11,210
training sample.

73
00:03:11,210 --> 00:03:13,180
That&#39;s this random sampling here--

74
00:03:13,180 --> 00:03:14,380
P hat giving Z star.

75
00:03:14,380 --> 00:03:16,210
This is now the bootstrap sample.

76
00:03:16,210 --> 00:03:19,840
Remember, we&#39;re going to use a superscript star to indicate a

77
00:03:19,840 --> 00:03:23,230
bootstrap sample as distinct from a training sample, which

78
00:03:23,230 --> 00:03:24,860
has no superscript.

79
00:03:24,860 --> 00:03:27,715
So this is one bootstrap draw.

80
00:03:27,715 --> 00:03:31,180
It&#39;s the sample of size n from our training sample now, our

81
00:03:31,180 --> 00:03:34,890
bootstrap sample, giving us the bootstrap data.

82
00:03:34,890 --> 00:03:36,770
And from that, we derive the estimate.

83
00:03:36,770 --> 00:03:40,250
Again, in this case, it&#39;s alpha.

84
00:03:40,250 --> 00:03:42,310
And we&#39;ll call it alpha hat star.

85
00:03:42,310 --> 00:03:46,190
So bootstrap sampling simply repeats this operation a few

86
00:03:46,190 --> 00:03:47,480
hundred times, say.

87
00:03:47,480 --> 00:03:49,940
For each time, we get a bootstrap sample of size n,

88
00:03:49,940 --> 00:03:54,160
and we get a bootstrap quantity alpha hat star.

89
00:03:54,160 --> 00:03:56,350
And then, the standard error of alpha hat star is the

90
00:03:56,350 --> 00:03:59,000
bootstrap estimate of standard error of alpha hat.

91
00:03:59,000 --> 00:04:01,710
Since there&#39;s nothing new here, we&#39;re simply describing

92
00:04:01,710 --> 00:04:05,240
what we already saw in more general terms, OK?

93
00:04:05,240 --> 00:04:08,830
But we can now think about how we carry this out in more

94
00:04:08,830 --> 00:04:11,960
complex situations.

95
00:04:11,960 --> 00:04:14,395
So in general, we need to figure out how we can carry

96
00:04:14,395 --> 00:04:15,920
out bootstrap sampling.

97
00:04:15,920 --> 00:04:18,970
For example, suppose we have a time series.

98
00:04:18,970 --> 00:04:23,190
So let&#39;s draw the time axis here.

99
00:04:23,190 --> 00:04:25,990
And we have a series, like for example stock price.

100
00:04:25,990 --> 00:04:31,154
And let&#39;s just draw some imaginary data, all right?

101
00:04:38,900 --> 00:04:40,530
So this is--

102
00:04:40,530 --> 00:04:41,350
let&#39;s call it y1.

103
00:04:41,350 --> 00:04:42,800
This is stock price at time one, stock price at

104
00:04:42,800 --> 00:04:44,715
time two, et cetera.

105
00:04:44,715 --> 00:04:49,710
And we want, for example, to predict the stock price for a

106
00:04:49,710 --> 00:04:51,840
given day from the previous day&#39;s stock price.

107
00:04:51,840 --> 00:04:54,230
So we&#39;ll fit a model, a regression model like we&#39;ve

108
00:04:54,230 --> 00:04:59,390
seen, to each stock price as a function of the stock price on

109
00:04:59,390 --> 00:05:00,850
the previous day.

110
00:05:00,850 --> 00:05:01,550
Well, that&#39;s fine.

111
00:05:01,550 --> 00:05:04,040
We can do that by least squares.

112
00:05:04,040 --> 00:05:06,660
But now, we might imagine doing bootstrap sampling like

113
00:05:06,660 --> 00:05:08,380
the way we just described where we sample with

114
00:05:08,380 --> 00:05:09,400
replacement from the data.

115
00:05:09,400 --> 00:05:13,130
Well, one problem with that that&#39;s a significant problem

116
00:05:13,130 --> 00:05:15,550
is that the data are not independent, right?

117
00:05:15,550 --> 00:05:17,630
There&#39;s correlation in the time series.

118
00:05:17,630 --> 00:05:20,480
We expect the stock price for a given day to be correlated

119
00:05:20,480 --> 00:05:22,140
with the stock price from the previous day.

120
00:05:22,140 --> 00:05:25,330
As a matter of fact, if we&#39;re trying to predict the stock

121
00:05:25,330 --> 00:05:27,250
price from a given day from the previous day, we hope

122
00:05:27,250 --> 00:05:28,390
there&#39;s correlation.

123
00:05:28,390 --> 00:05:30,730
If they were independent, the prediction

124
00:05:30,730 --> 00:05:32,450
wouldn&#39;t be very useful.

125
00:05:32,450 --> 00:05:34,250
But this creates a problem for the bootstrap.

126
00:05:34,250 --> 00:05:40,830
Because in the schematic, we were sampling here where we

127
00:05:40,830 --> 00:05:46,300
assumed that the sampling was IID from the population.

128
00:05:46,300 --> 00:05:48,240
But in this situation, that&#39;s not a reasonable assumption.

129
00:05:48,240 --> 00:05:51,080
Because the observations are not independent.

130
00:05:51,080 --> 00:05:55,050
So in general, when you set up the bootstrap and arrange for

131
00:05:55,050 --> 00:05:58,830
the sampling, you must figure out what parts of the data are

132
00:05:58,830 --> 00:05:59,840
independent.

133
00:05:59,840 --> 00:06:02,290
So one thing people do in a time series--

134
00:06:02,290 --> 00:06:05,930
because the observations are not independent-- to correlate

135
00:06:05,930 --> 00:06:09,250
across time is to use what&#39;s called the block bootstrap.

136
00:06:09,250 --> 00:06:11,370
The block bootstrap divides the data up into blocks.

137
00:06:14,390 --> 00:06:16,830
And between blocks, one assumes that things are

138
00:06:16,830 --> 00:06:18,350
independent.

139
00:06:18,350 --> 00:06:19,560
Oops, my spelling&#39;s not good.

140
00:06:19,560 --> 00:06:21,550
OK, so for example, if we use a block size

141
00:06:21,550 --> 00:06:23,560
of three, we might--

142
00:06:23,560 --> 00:06:25,080
these would be the first block, these three

143
00:06:25,080 --> 00:06:26,330
observations.

144
00:06:26,330 --> 00:06:27,540
These three would be the second block.

145
00:06:27,540 --> 00:06:28,980
These would be the next block.

146
00:06:28,980 --> 00:06:31,680
And now our sampling units are not individual observations.

147
00:06:31,680 --> 00:06:33,180
But they&#39;re entire blocks.

148
00:06:33,180 --> 00:06:34,970
So we would sample with replacement from all the

149
00:06:34,970 --> 00:06:38,000
blocks and then paste them together

150
00:06:38,000 --> 00:06:39,770
into a new time series.

151
00:06:39,770 --> 00:06:41,820
In other words, if this guy&#39;s sampled, he might become the

152
00:06:41,820 --> 00:06:43,910
first block, second block, et cetera.

153
00:06:43,910 --> 00:06:47,050
And then, we paste them together in order.

154
00:06:47,050 --> 00:06:50,380
And that becomes the bootstrap sample to which we apply the

155
00:06:50,380 --> 00:06:52,440
estimate-- in this case, a regression model.

156
00:06:52,440 --> 00:06:54,630
So the point is you have to sample the things that are

157
00:06:54,630 --> 00:06:56,240
uncorrelated.

158
00:06:56,240 --> 00:06:58,040
You have to arrange for--

159
00:06:58,040 --> 00:07:00,910
find the parts of the data that are uncorrelated and use

160
00:07:00,910 --> 00:07:03,000
that as a basis for bootstrap sampling.

161
00:07:03,000 --> 00:07:07,850
In this case, we use a block of size three under the

162
00:07:07,850 --> 00:07:11,500
assumption that beyond a time lag of three, things are

163
00:07:11,500 --> 00:07:12,770
somewhat uncorrelated.

164
00:07:12,770 --> 00:07:15,070
But within a block, we expect correlation.

165
00:07:15,070 --> 00:07:18,630
So we keep the blocks intact and sample them as units.

166
00:07:18,630 --> 00:07:19,880
That&#39;s called the block bootstrap.

167
00:07:22,410 --> 00:07:25,450
I say that here, OK?

168
00:07:25,450 --> 00:07:28,040
So we talked about the bootstrap for standard errors.

169
00:07:28,040 --> 00:07:30,040
The main use of the bootstrap is to estimate the standard

170
00:07:30,040 --> 00:07:33,170
errors of an estimate like the alpha hat in

171
00:07:33,170 --> 00:07:35,190
our investment example.

172
00:07:35,190 --> 00:07:37,750
Another very common use of the bootstrap is

173
00:07:37,750 --> 00:07:39,620
for confidence interval.

174
00:07:39,620 --> 00:07:42,410
So let&#39;s go back to confidence interval for our parameters.

175
00:07:42,410 --> 00:07:45,590
Let&#39;s go back to slide 29.

176
00:07:45,590 --> 00:07:47,540
And remember, this is the histogram we got from the

177
00:07:47,540 --> 00:07:50,510
bootstrap for the values of alpha hat over bootstrap

178
00:07:50,510 --> 00:07:53,610
sampling, 1,000 bootstrap samples.

179
00:07:53,610 --> 00:07:56,750
And if you look at this histogram, a reasonable way to

180
00:07:56,750 --> 00:07:58,960
derive a confidence interval is to take the percentiles

181
00:07:58,960 --> 00:08:00,750
from this histogram.

182
00:08:00,750 --> 00:08:04,200
Suppose I want a 0.9 confidence interval so that it

183
00:08:04,200 --> 00:08:07,390
contains a true value with probability 90%.

184
00:08:07,390 --> 00:08:09,370
It makes sense to grab the fifth and

185
00:08:09,370 --> 00:08:12,155
95th percent quantiles.

186
00:08:12,155 --> 00:08:17,290
In other words, find the 5% point of this histogram and

187
00:08:17,290 --> 00:08:20,210
the 95% point of that histogram.

188
00:08:20,210 --> 00:08:21,270
There&#39;s 1,000 points here.

189
00:08:21,270 --> 00:08:26,200
So actually, the 5% point would be the 50th biggest and

190
00:08:26,200 --> 00:08:28,570
9/50 biggest value of alpha.

191
00:08:28,570 --> 00:08:30,450
You mean smallest and biggest.

192
00:08:30,450 --> 00:08:31,630
Did I say that wrong?

193
00:08:31,630 --> 00:08:32,520
You said it wrong.

194
00:08:32,520 --> 00:08:35,490
I&#39;m sure they understood, just like I did.

195
00:08:35,490 --> 00:08:39,850
OK, so if we do that, that provides a confidence

196
00:08:39,850 --> 00:08:41,100
interval for alpha.

197
00:08:41,100 --> 00:08:42,020
And what do we actually get?

198
00:08:42,020 --> 00:08:44,550
I&#39;ve got that back on the slide.

199
00:08:44,550 --> 00:08:48,190
It&#39;s that, so 0.43 and 0.72.

200
00:08:48,190 --> 00:08:51,420
So this is actually an appropriate confidence

201
00:08:51,420 --> 00:08:54,390
interval for alpha.

202
00:08:54,390 --> 00:08:57,230
And remember how to interpret this confidence interval.

203
00:08:57,230 --> 00:09:00,820
What this means is that if we were to repeat this experiment

204
00:09:00,820 --> 00:09:04,980
from the population many times, it would be the case

205
00:09:04,980 --> 00:09:06,890
that the confidence interval that we obtain would contain

206
00:09:06,890 --> 00:09:10,120
the true value of alpha 90% of the time.

207
00:09:10,120 --> 00:09:12,660
That&#39;s what a 90% confidence interval is.

208
00:09:12,660 --> 00:09:14,130
We talked about that earlier.

209
00:09:14,130 --> 00:09:15,650
This particular way of constructing intervals is

210
00:09:15,650 --> 00:09:18,170
called a bootstrap percentile interval.

211
00:09:18,170 --> 00:09:21,640
And there&#39;s actually an entire field in statistics to do with

212
00:09:21,640 --> 00:09:23,490
confidence intervals in the bootstrap.

213
00:09:23,490 --> 00:09:25,742
And there&#39;s many, many, many papers and books that have

214
00:09:25,742 --> 00:09:26,920
been written about this topic.

215
00:09:26,920 --> 00:09:29,470
This bootstrap percentile interval is the simplest way

216
00:09:29,470 --> 00:09:31,430
of constructing a confidence interval from the bootstrap.

217
00:09:31,430 --> 00:09:34,000
And it&#39;s very useful.

218
00:09:34,000 --> 00:09:36,820
We just use the histogram of bootstrap values themselves,

219
00:09:36,820 --> 00:09:39,640
and use their percentiles.

220
00:09:39,640 --> 00:09:42,570
So we&#39;ve talked about the bootstrap for standard errors

221
00:09:42,570 --> 00:09:43,885
and confidence intervals.

222
00:09:43,885 --> 00:09:46,730
How about prediction error like misclassification error

223
00:09:46,730 --> 00:09:49,360
that we&#39;ve seen in the course already?

224
00:09:49,360 --> 00:09:51,360
Well, the major tool we talked about for that was

225
00:09:51,360 --> 00:09:52,560
cross-validation.

226
00:09:52,560 --> 00:09:53,490
And let&#39;s think back on

227
00:09:53,490 --> 00:09:55,580
cross-validation, how it worked.

228
00:09:55,580 --> 00:09:58,360
We have K folds in K fold cross-validation.

229
00:09:58,360 --> 00:10:02,240
We divide the data up into K parts, let&#39;s say five.

230
00:10:02,240 --> 00:10:03,490
And I&#39;ll just draw this again.

231
00:10:06,710 --> 00:10:11,560
Remember, what we did is our five parts created at random K

232
00:10:11,560 --> 00:10:14,050
fold cross-validation is like, remember, a five act

233
00:10:14,050 --> 00:10:17,040
play if K is 5.

234
00:10:17,040 --> 00:10:19,150
At one stage of the play, these four are the training

235
00:10:19,150 --> 00:10:21,570
set, these four parts.

236
00:10:21,570 --> 00:10:27,790
And the remaining fifth part is the validations part, set.

237
00:10:27,790 --> 00:10:31,440
And cross-validation fits to the four parts, fits a model,

238
00:10:31,440 --> 00:10:34,770
and then uses that model to predict the fifth part.

239
00:10:34,770 --> 00:10:38,900
And then, in turn, this guy gets to play the role of the

240
00:10:38,900 --> 00:10:40,370
validation set in the next stage, and

241
00:10:40,370 --> 00:10:41,000
this guy, et cetera.

242
00:10:41,000 --> 00:10:42,960
And this is five stages.

243
00:10:42,960 --> 00:10:45,520
But a crucial part of cross-validation was that when

244
00:10:45,520 --> 00:10:48,160
we do one stage like this, there&#39;s no overlap between the

245
00:10:48,160 --> 00:10:50,170
training set and the validation set.

246
00:10:50,170 --> 00:10:52,280
In other words, the observations in one do not

247
00:10:52,280 --> 00:10:53,960
appear in the other.

248
00:10:53,960 --> 00:10:56,090
And that&#39;s important, because we&#39;re trying to get an idea of

249
00:10:56,090 --> 00:10:58,050
test set error on new data.

250
00:10:58,050 --> 00:11:04,390
So cross-validation is taking a piece of data, separating it

251
00:11:04,390 --> 00:11:07,040
out from the training set so that when I fit on this data,

252
00:11:07,040 --> 00:11:09,150
predicted on this data, this data is, in a sense, new.

253
00:11:09,150 --> 00:11:13,500
It hasn&#39;t been seen by the model train on the first four.

254
00:11:13,500 --> 00:11:15,950
So there&#39;s a separation, a clean separation, between

255
00:11:15,950 --> 00:11:18,730
training and validation.

256
00:11:18,730 --> 00:11:21,240
Well, what if we were to try to use the bootstrap to

257
00:11:21,240 --> 00:11:23,390
estimate prediction error?

258
00:11:23,390 --> 00:11:27,760
Let&#39;s just draw in the bootstrap sampling process.

259
00:11:27,760 --> 00:11:29,510
Here&#39;s my training set.

260
00:11:29,510 --> 00:11:32,390
And I&#39;m going to draw samples with replacement from the

261
00:11:32,390 --> 00:11:34,620
training set, bootstrap samples, each one of the same

262
00:11:34,620 --> 00:11:36,940
size, and a few hundred them.

263
00:11:36,940 --> 00:11:40,550
Well, the first kind of obvious idea is to say, well,

264
00:11:40,550 --> 00:11:44,860
let&#39;s train on a bootstrap data set and then predict the

265
00:11:44,860 --> 00:11:48,420
original training set as my validation set.

266
00:11:48,420 --> 00:11:49,870
I can do that for each bootstrap sample.

267
00:11:49,870 --> 00:11:52,140
Each bootstrap sample gets to play the role of the training

268
00:11:52,140 --> 00:11:52,940
set to fit.

269
00:11:52,940 --> 00:11:55,020
And then, I&#39;m going to predict my original training sample as

270
00:11:55,020 --> 00:11:56,900
my validation set.

271
00:11:56,900 --> 00:11:58,330
Well, there&#39;s a big problem with that.

272
00:11:58,330 --> 00:12:02,990
And the problem is there&#39;s an overlap between the bootstrap

273
00:12:02,990 --> 00:12:05,080
data sets and the original data set.

274
00:12:05,080 --> 00:12:07,280
In particular, about 2/3 of the original data points

275
00:12:07,280 --> 00:12:09,510
appear in each bootstrap sample.

276
00:12:09,510 --> 00:12:11,920
And you should think about how to prove this.

277
00:12:11,920 --> 00:12:16,670
It&#39;s not hard, but you&#39;ll find out that about 2/3 of these

278
00:12:16,670 --> 00:12:19,430
points, so the training set points, are in

279
00:12:19,430 --> 00:12:21,420
the bootstrap sample.

280
00:12:21,420 --> 00:12:25,010
This creates a problem, because now when I train here

281
00:12:25,010 --> 00:12:28,520
and I do the prediction of a training set, 2/3 of the

282
00:12:28,520 --> 00:12:33,570
points in this training set have already

283
00:12:33,570 --> 00:12:36,460
been seen by the model.

284
00:12:36,460 --> 00:12:38,260
Because they&#39;re in the bootstrap data set.

285
00:12:38,260 --> 00:12:41,310
So on average, this 2/3 overlap means that most of the

286
00:12:41,310 --> 00:12:43,640
training points are not novel.

287
00:12:43,640 --> 00:12:50,505
So this is a big problem, because the prediction error

288
00:12:50,505 --> 00:12:53,460
from this process will be biased downward.

289
00:12:53,460 --> 00:12:55,250
It&#39;ll be a lot lower than the actual prediction error,

290
00:12:55,250 --> 00:12:58,910
because 2/3 of the points I&#39;m predicting I&#39;ve already seen

291
00:12:58,910 --> 00:13:00,870
in the bootstrap data set.

292
00:13:00,870 --> 00:13:05,290
So this is not a good way of estimating prediction error.

293
00:13:05,290 --> 00:13:07,660
OK, I say that it underestimates the true

294
00:13:07,660 --> 00:13:08,910
prediction error quite dramatically.

295
00:13:13,160 --> 00:13:14,600
Now, you can think about it the other way around.

296
00:13:14,600 --> 00:13:17,420
You could train on the training set and use the

297
00:13:17,420 --> 00:13:19,970
bootstrap samples as the validations sets.

298
00:13:19,970 --> 00:13:21,190
And that&#39;s even worse.

299
00:13:21,190 --> 00:13:22,730
And you can think about why that is.

300
00:13:22,730 --> 00:13:23,965
So it&#39;s even worse in the sense that it&#39;s going to be

301
00:13:23,965 --> 00:13:25,225
even more biased.

302
00:13:25,225 --> 00:13:28,150
Well, how do you fix this problem?

303
00:13:28,150 --> 00:13:32,230
You can fix it by, when you train on the bootstrap sample

304
00:13:32,230 --> 00:13:35,400
and then predict the training sample, just recording the

305
00:13:35,400 --> 00:13:37,960
predictions for the points that did not occur in the

306
00:13:37,960 --> 00:13:40,030
bootstrap sample-- in other words, the points that are

307
00:13:40,030 --> 00:13:41,580
actually novel points.

308
00:13:41,580 --> 00:13:43,470
But then, this gets complicated.

309
00:13:43,470 --> 00:13:46,310
And in the end, it&#39;s really not worth it.

310
00:13:46,310 --> 00:13:50,050
If you push this idea to its conclusion, you can get

311
00:13:50,050 --> 00:13:51,850
something which is about as good as cross-validation.

312
00:13:51,850 --> 00:13:53,040
But it&#39;s much more complicated.

313
00:13:53,040 --> 00:13:57,450
So our view is for this particular problem,

314
00:13:57,450 --> 00:14:01,400
cross-validation is easier, and better, and

315
00:14:01,400 --> 00:14:04,220
the thing we recommend.

316
00:14:04,220 --> 00:14:05,760
If I can just interrupt, Rob--

317
00:14:05,760 --> 00:14:07,485
that actually brings up an interesting point.

318
00:14:07,485 --> 00:14:10,500
A lot of the time, we have simple methods like

319
00:14:10,500 --> 00:14:11,870
cross-validation.

320
00:14:11,870 --> 00:14:15,270
And then, a new method comes along like using bootstrap to

321
00:14:15,270 --> 00:14:16,820
estimate prediction error.

322
00:14:16,820 --> 00:14:19,630
And we see it&#39;s quite a lot more complicated.

323
00:14:19,630 --> 00:14:21,103
And you don&#39;t get much in return.

324
00:14:21,103 --> 00:14:25,600
And so our general philosophy is if you can get the job done

325
00:14:25,600 --> 00:14:28,800
with a simple method, it&#39;s far better than using a more

326
00:14:28,800 --> 00:14:30,730
complicated method just because it maybe

327
00:14:30,730 --> 00:14:32,790
looks sexy or whatever.

328
00:14:32,790 --> 00:14:34,370
So keep it simple-- that&#39;s the idea.

