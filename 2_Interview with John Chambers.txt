Well, we have a guest here today, Dr. John Chambers.
John was the inventor of the S language, which is the
language that we use in R. John was also my department
head at AT&T Bell Labs when I worked there in
the '80s and '90s.
So John, welcome.
Great to be here.
Thank you and please tell us about S and how it became R.
It's an interesting story actually.
It's an interesting combination of ideas, and the
context for the ideas and outside events that we had no
control over.
It has a very specific birth-date actually, which is
the 5th of May, 1976.
And that was a day on which five of us at Bell Labs in
Murray Hill sat down in the little conference room and
started to talk about what we might do to create an
interactive system, as we called it at that time.
But it's very important.
It's part of the story that was far from the beginning of
statistical computing research at Bell Labs.
My own involvement had gone on for more than a
decade before that.
And as a another example, about a year before that, we
hired a really bright young guy named Rick Becker.
And Rick and I, the first thing that we worked on
together was a system of software for statistical
graphics, for scatter plots and other kinds of things like
that called GRZ.
And you've probably never heard of GRZ, but you've used
it because the base graphics in R is essentially designed
on the way that we structured GRZ.
Never knew that.
And in addition, we had lots of other software.
Numerical software, random number generation, data
management, all that kind of stuff.
The catch was, that all of it was in the form of FORTRAN
call subroutines.
So in order to use it, people had to construct a FORTRAN
main program, job control, and all that kind of stuff.
And the result was that there was a delay, and lots of
people were involved, and by the time you've got the
results back you'd kind of forgotten what the idea was in
the first place.
So our goal was to provide an interactive system, where the
people actually doing the statistical analysis, or doing
the research, could sit down themselves and express what
they wanted in some fairly natural way and get the
results back right away.
But, at the same time, and this is also important, we
wanted them to still have access to the best
computational methods that existed, regardless of where
they came from, or who had written them and including
things that would be developed later on.
So that was the basic philosophy.
And when you think about it, that's not a bad description
of what we're trying to do nowadays with R. So in the
first, next few months we did put together an initial
version of the system and started to have people use it
in the statistics research area and other colleagues at
Murray Hill.
That takes us to sort of late in the 1970s,
around 1978 or so.
And, meanwhile, the next event on the floor above us at
Murray Hill, there were some guys in computer science
research who were busy creating a new kind of
operating system, which eventually was called Unix.
And in particular, around 1978 or so, the new version of Unix
was developed.
It was based on the C programming language, and was
portable amongst different computers.
In particular, it was portable to 32-bit machines, which
meant that it was now a candidate for
doing scientific computing.
Before it had been on a 16-bit machine.
Rick and I immediately realized that this was the way
that we were going to get a portable version of S,
something that we had been worrying about for awhile.
So in the late '70s, we rewrote S to use the C
language and Unix operating system.
That was the first version that was licensed for people
outside of AT&T to use.
And there too, we piggybacked off Unix because the Unix
folks had arranged with AT&T to license their software,
their operating system.
And in particular, to license it with a very favorable rate
to universities, basically free to universities, just for
the cost of copying the tape.
We managed to get the same arrangement for S, and so, at
that point, we started to have outside users, mainly
universities where there was a lot of interest in statistics,
in computing, and things like that.
Carnegie Mellon, Toronto, Berkeley.
And John, was that S very similar to what we use today?
Not so similar.
There were two books that Rick and I wrote
that describe that.
If you looked at it and just looked at what somebody had
written down say to do a linear regression, it would
look similar.
But as soon as you started to do anything nontrivial, it was
very different.
And, in fact, that's sort of the next part of the story.
So then some other events started to take place.
One was that in 1981, I left statistics for a few years and
went to head what was called the Advance Software
Department.
Their job was primarily to produce computing tools for
the company, particularly for what would
nowadays be called analytics.
And so while I was there, I started to look at some other
ideas and programming languages and started to write
a new language, a different language called a quadratic
programming environment, which originally wasn't going to
have any connection directly to S at all.
But while all that was happening, on a much, much
larger scale, AT&T, the old Bell system, agreed to be
split up, to divest itself of all of the local telephone
companies, in response to an anti-trust suit from the
federal government.
This took place between 1981, 1983.
As part of that, Bell Labs spun off a fair fraction of
itself, including research, to a new company called Bell
Corp. And as part of the rearrangements and
reorganizations and everything that went on at that time, I
came back to statistics as head of the Statistics and
Data Analysis Research Department.
And Rick and I got back together.
And we decided to merge the sort of stuff I've been
working on with what he'd been doing to improve S itself, and
to create a new version, what we call the New S Language.
And a book that describes that.
That's probably the first one I got to know.
It probably is.
There were few universities who got into the old S, but
this is when S began to really take off with universities and
research labs, and to some extent, third party resellers.
And then, of course, as you very well know, we went on to
also produce the Statistical Models in S effort that you
and I edited.
And along with that came the first version of object
oriented programming for S.
So this takes us now to the middle--
I notice how much more play that book gets than this
grubby old blue book.
Anyway, so that now takes us to about the
middle of the 1990s.
Things were kind of taking off and doing quite well.
And now, we come to the next event, which is in 1996.
Ross Ihaka and Robert Gentleman published a paper on
something they just called a language for data analysis and
graphics, and just happened to have the name R.
So this expressed some ideas, particularly Ross had about
better ways to do some of the things that were done.
But as Ross was prone to say in talks at the time, it was a
language that was not unlike S. And in fact, once it was
out there, there's a lot of enthusiasm amongst a number of
people to make it into a free open source
clone of the S language.
Over the next few years, in the late 1990s, a group, which
came to be called R Corp, got together and did that.
Ross and Robert very wisely and very generously,
transferred control over R to the R Corp group.
And at that point, it really started to take off.
And the process was to replicate the facilities that
were described in the blue book, and for the most part,
in the white book in a new open source
and portable language.
And that's R.
The event there, which also has a very specific date, was
on February 29, 2000, which by the way, is
a very unique date.
And on that date version 1.0 of R was produced.
I wasn't part of R Corp at that time, but I was very
friendly with them and one of my most treasured souvenirs is
serial number one of the CD-ROMs that were produced at
that time for R, autographed by all the members of R Corp.
Very treasured memento.
So that basically, in a sense, that was it.
And the rest has kind of been history.
R has really taken off and has introduced a number of
additional ideas that we never had and there are now millions
of users and many thousands of packages and on the whole,
it's a great thing, and I'm just overwhelmed by it all.
Well, I think that the generations of statisticians,
that today's generation, can be really grateful for this.
R is wonderful.
I've used it for the last 10 years.
Love it.
Have written packages to.
And it's just such a wonderful environment to be able to work
in, and it's free.
So really good and very high quality.
I think the most important thing from my point-of-view is
that it's had a very strong effect, I'd almost be tempted
to call it a revolutionary effect, in the way new results
in statistics are communicated.
Used to be, people would just write a paper and then you
would write to the author and try to figure out if there is
some way you could implement what he'd done in
some form or other.
For many things now, not all, but many things now, people
produce the code, they produce an R package, and instantly,
everyone else can use what they've got freely and
contribute their ideas to let things evolve.
And that I think is, to my mind, the most beneficial
result that's happened.
Well, thank you very much, John.
My pleasure.
John retired from Bell Labs a few years back, and we've
managed to lure him to Stanford where he is a
consulting professor in the Statistics Department.
Thanks very much.